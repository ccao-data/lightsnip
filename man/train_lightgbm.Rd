% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lightgbm.R
\name{train_lightgbm}
\alias{train_lightgbm}
\title{Boosted trees via LightGBM}
\usage{
train_lightgbm(
  x,
  y,
  num_iterations = 10,
  max_depth = 17,
  num_leaves = 31,
  link_max_depth = FALSE,
  add_to_linked_depth = 2L,
  categorical_feature = NULL,
  weight = NULL,
  validation = 0,
  sample_type = "random",
  early_stop = NULL,
  max_bin = NULL,
  feature_pre_filter = FALSE,
  free_raw_data = TRUE,
  verbose = 0,
  ...
)
}
\arguments{
\item{x}{A matrix of predictors.}

\item{y}{A numeric vector of outcome data.}

\item{num_iterations}{Integer value for the number of iterations (trees)
to grow.}

\item{max_depth}{Integer value for the maximum leaf distance from the root
node.}

\item{num_leaves}{Integer value for the maximum possible number of leaves
in one tree.}

\item{link_max_depth}{Logical, default FALSE. When TRUE, and when
\code{max_depth} is unconstrained \code{-1}, then \code{max_depth} will
be set to \code{floor(log2(num_leaves)) + link_max_depth_add}.}

\item{add_to_linked_depth}{Integer value to add to \code{max_depth} when it
is linked to \code{num_leaves}.}

\item{categorical_feature}{A character vector of feature names or an
integer vector with the indices of the features.}

\item{weight}{A numeric vector of sample weights. Should be the same length
as the number of rows of \code{x}.}

\item{validation}{A positive number on \code{[0, 1)}. \code{validation} is
the proportion of data in \code{x} and \code{y} that is used for
performance assessment and early stopping.}

\item{sample_type}{The sampling method for the validation set. Can be either
"random" (a completely random sample) or "recent" (the last X% of rows,
where X is the proportion specified by \code{validation}).}

\item{early_stop}{An integer or \code{NULL}. If an integer, it is the
number of iterations without improvement before stopping.
Must be set when \code{validation} is > 0.}

\item{max_bin}{Max number of bins that feature values will be bucketed in.}

\item{feature_pre_filter}{Tell LightGBM to ignore the features that are
unsplittable based on \code{min_data_in_leaf}.}

\item{free_raw_data}{LightGBM constructs its data format, called a "Dataset",
from tabular data. By default, that Dataset object on the R side does not
keep a copy of the raw data. This reduces LightGBM's memory consumption,
but it means that the Dataset object cannot be changed after it has been
constructed. If you'd prefer to be able to change the Dataset object after
construction, set \code{free_raw_data = FALSE}. Useful for debugging.}

\item{verbose}{Integer. < 0: Fatal, = 0: Error (Warning), = 1: Info,
> 1: Debug.}

\item{...}{Engine arguments, hyperparameters, etc. that are passed on to
\code{\link[lightgbm]{lgb.train}}.}
}
\value{
A fitted \code{lgb.Booster} object.
}
\description{
Wrapper for \code{\link[lightgbm]{lgb.train}} tree-based models
with some expanded/advanced options.
}
\keyword{internal}
